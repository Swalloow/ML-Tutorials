{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark with Scala\n",
    "Apache Toree - Jupyter Notebook testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(1, 4, 9, 16, 25, 36, 49, 64, 81, 100)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize(1 to 100).map(x => x*x).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(4, 16, 36, 64, 100, 144, 196, 256, 324, 400)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize(1 to 100).\n",
    "  filter(x => x % 2 == 0).\n",
    "  map(x => x * x).\n",
    "  take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(hello,3)\n",
       "(two,1)\n",
       "(one,1)\n",
       "(world,1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val lines = Array(\"hello world\", \"hello one\", \"hello two\")\n",
    "sc.parallelize(lines).\n",
    "  flatMap(line => line.split(\"\\\\W+\")).\n",
    "  map(word => (word,1)).\n",
    "  reduceByKey(_+_).\n",
    "  sortBy({case (word,count) => count},false).\n",
    "  collect.\n",
    "  mkString(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// Grab URL contents\n",
    "def getUrl(url:String):String = \n",
    "  scala.io.Source.fromURL(url).mkString\n",
    "\n",
    "// Write file\n",
    "def fileWrite(path:String,contents:String) = {\n",
    "  import java.io.{PrintWriter,File}\n",
    "  val writer = new PrintWriter(new File(path))\n",
    "  writer.write(contents)\n",
    "  writer.close\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Prices\n",
    "Get the historical stock price of AAPL and save it in AAPL.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL.csv\n"
     ]
    }
   ],
   "source": [
    "val symbol = \"AAPL\"\n",
    "val baseUrl = \"http://real-chart.finance.yahoo.com\"\n",
    "val url = s\"${baseUrl}/table.csv?s=${symbol}&g=d&ignore=.csv\"\n",
    "val csv = getUrl(url)\n",
    "val csvFile = s\"${symbol}.csv\"\n",
    "fileWrite(csvFile, csv)\n",
    "println(csvFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highest Prices\n",
    "Find the days with the highest adjusted close prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(141.460007,2017-03-20)\n",
      "(141.419998,2017-03-22)\n",
      "(140.919998,2017-03-23)\n",
      "(140.690002,2017-03-16)\n",
      "(140.639999,2017-03-24)\n"
     ]
    }
   ],
   "source": [
    "val stockRdd = sc.textFile(csvFile).\n",
    "  filter(line => line matches \".*\\\\d.*\").\n",
    "  map(line => line.split(\",\")).\n",
    "  map(fields => (fields(6).toDouble,fields(0))).\n",
    "  sortBy({case (close,date) => close},false)\n",
    "\n",
    "stockRdd.take(5).foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CSV\n",
    "Now lets use SQL to analyze the stock instead of directly manipulating records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:17: error: not found: value sqlContext\n",
       "       val df = sqlContext.read.\n",
       "                ^\n",
       "StackTrace: "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = sqlContext.read.\n",
    "    format(\"com.databricks.spark.csv\").\n",
    "    option(\"header\", \"true\").\n",
    "    option(\"inferSchema\", \"true\").\n",
    "    load(\"AAPL.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:18: error: not found: value df\n",
       "       df.select(\"Date\",\"Adj Close\").show\n",
       "       ^\n",
       "StackTrace: "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"Date\",\"Adj Close\").show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Queries\n",
    "Register it as a SQL table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:18: error: not found: value df\n",
       "       df.registerTempTable(\"aapl\")\n",
       "       ^\n",
       "StackTrace: "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.registerTempTable(\"aapl\")\n",
    "sqlContext.sql(\"SELECT COUNT(1) AS row_count FROM aapl\").show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highest prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:18: error: not found: value sqlContext\n",
       "       sqlContext.sql(\"SELECT MAX(`Adj Close`) AS max_close FROM aapl\").show\n",
       "       ^\n",
       "StackTrace: "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext.sql(\"SELECT MAX(`Adj Close`) AS max_close FROM aapl\").show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:18: error: not found: value sqlContext\n",
       "sqlContext.sql(\"\"\"SELECT Date,`Adj Close` FROM aapl\n",
       "^\n",
       "StackTrace: "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext.sql(\"\"\"SELECT Date,`Adj Close` FROM aapl \n",
    "    ORDER BY `Adj Close` DESC LIMIT 5\"\"\").show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "file_extension": ".scala",
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
